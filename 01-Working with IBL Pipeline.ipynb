{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the pipeline\n",
    "\n",
    "Here we get to explore the IBL pipeline and start performing some analysis on it.\n",
    "\n",
    "First thing first, let's **import the IBL pipeline package**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibl_pipeline import subject, acquisition, action, behavior, reference\n",
    "from ibl_pipeline.analyses.behavior import PsychResults\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these modules correspond to a DataJoint **schema** -- or a collection of related tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataJoint Graph offers a nice way to visualize the pipeline. \n",
    "\n",
    "**NOTE: this may not work if you don't have Graphviz installed on your system.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the trial set with some minimum number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_set_keys = (behavior.TrialSet() & 'n_trials > 600').fetch('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trial_set_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And not focus on one such trial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = trial_set_keys[0]\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior.TrialSet & key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and all trials falling under that particular trial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior.TrialSet.Trial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing some statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let's compute some statistics on the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning it into a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a new table for your own, start by creating a schema in which you'll place your new table. Most users are given privileges to create any schema starting with their username followed by `_`, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('user_eywalker_tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a new computed table that would store the computed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing psychometric curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to look at the proportion of right choices (CCW) as contrast difference between left and right stimulus changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice, cont_left, cont_right = (behavior.TrialSet.Trial & key).fetch('trial_response_choice', \n",
    "                                                                      'trial_stim_contrast_left', \n",
    "                                                                      'trial_stim_contrast_right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_contrasts = cont_right - cont_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_choices = choice == 'CCW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_signed_contrasts = np.unique(signed_contrasts)\n",
    "\n",
    "total_trials = []\n",
    "right_trials = []\n",
    "\n",
    "for cont in unique_signed_contrasts:\n",
    "    matching = (signed_contrasts == cont)\n",
    "    total_trials.append(np.sum(matching))\n",
    "    right_trials.append(np.sum(right_choices[matching]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_right_trials = np.divide(right_trials, total_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.plot(unique_signed_contrasts * 100, prop_right_trials)\n",
    "ax.set_xlabel('Signed Contrast (%)')\n",
    "ax.set_ylabel('P(right choice)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have information on how choice changes across signed contrasts, let's try fitting psychometric curves. Function for fitting psychometric curves are given in `ibl_pipeline.utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibl_pipeline.utils import psychofit as psy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars, L = psy.mle_fit_psycho(\n",
    "        np.vstack([unique_signed_contrasts * 100, total_trials, prop_right_trials]),\n",
    "        P_model='erf_psycho_2gammas',\n",
    "        parstart=np.array([np.mean(unique_signed_contrasts), 20., 0.05, 0.05]),\n",
    "        parmin=np.array([np.min(unique_signed_contrasts), 0., 0., 0.]),\n",
    "        parmax=np.array([np.max(unique_signed_contrasts), 100., 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-100, 100)\n",
    "y = psy.erf_psycho_2gammas(pars, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.plot(unique_signed_contrasts * 100, prop_right_trials)\n",
    "ax.plot(x, y)\n",
    "ax.set_xlabel('Signed Contrast (%)')\n",
    "ax.set_ylabel('P(right choice)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus round - using DataJoint all the way through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out you can perform all of the above steps purely within DataJoint query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = behavior.TrialSet.Trial & key\n",
    "\n",
    "t_info = trials.proj('trial_response_choice', signed_contrast='trial_stim_contrast_right - trial_stim_contrast_left')\n",
    "q = dj.U('signed_contrast').aggr(t_info, n='count(*)', n_right='sum(trial_response_choice=\"CCW\")')\n",
    "result = q.proj('n', 'n_right', 'signed_contrast', prop_right='n_right / n')\n",
    "\n",
    "right_trials, total_trials, prop_right_trials, signed_contrasts = result.fetch('n_right', 'n', 'prop_right', 'signed_contrast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.plot(signed_contrasts * 100, prop_right_trials)\n",
    "ax.set_xlabel('Signed Contrast (%)')\n",
    "ax.set_ylabel('P(right choice)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now gives us enough information to understand how `PsychResults` table is implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PsychResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PsychResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PsychResults.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an exact replica of PsychResults class definition as found in `ibl_pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class PsychResults(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> behavior.TrialSet\n",
    "    ---\n",
    "    performance:            float   # percentage correct in this session\n",
    "    performance_easy=null:  float   # percentage correct of easy trials in this session\n",
    "    signed_contrasts:       blob    # contrasts used in this session, negative when on the left\n",
    "    n_trials_stim:          blob    # number of trials for each contrast\n",
    "    n_trials_stim_right:    blob    # number of reporting \"right\" trials for each contrast\n",
    "    prob_choose_right:      blob    # probability of choosing right, same size as contrasts\n",
    "    threshold:              float\n",
    "    bias:                   float\n",
    "    lapse_low:              float\n",
    "    lapse_high:             float\n",
    "    \"\"\"\n",
    "\n",
    "    def make(self, key):\n",
    "\n",
    "        trials = behavior.TrialSet.Trial & key\n",
    "        psych_results_tmp = utils.compute_psych_pars(trials)\n",
    "        psych_results = {**key, **psych_results_tmp}\n",
    "\n",
    "        performance_easy = utils.compute_performance_easy(trials)\n",
    "        if performance_easy:\n",
    "            psych_results['performance_easy'] = performance_easy\n",
    "\n",
    "        n_trials, n_correct_trials = (behavior.TrialSet & key).fetch1(\n",
    "            'n_trials', 'n_correct_trials')\n",
    "        psych_results['performance'] = n_correct_trials/n_trials\n",
    "        self.insert1(psych_results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the logic is inside the `compute_psych_pars` utility function:\n",
    "\n",
    "```python\n",
    "def compute_psych_pars(trials):\n",
    "\n",
    "    trials = trials.proj(\n",
    "        'trial_response_choice',\n",
    "        signed_contrast='trial_stim_contrast_right \\\n",
    "        - trial_stim_contrast_left')\n",
    "    q_all = dj.U('signed_contrast').aggr(trials, n='count(*)')\n",
    "    q_right = dj.U('signed_contrast').aggr(\n",
    "        trials, n_right='sum(trial_response_choice=\"CCW\")')\n",
    "    signed_contrasts, n_trials_stim = q_all.fetch(\n",
    "        'signed_contrast', 'n'\n",
    "    )\n",
    "    signed_contrasts = signed_contrasts.astype(float)\n",
    "    n_trials_stim = n_trials_stim.astype(int)\n",
    "    n_trials_stim_right = q_right.fetch('n_right').astype(int)\n",
    "    prob_choose_right = np.divide(n_trials_stim_right,\n",
    "                                  n_trials_stim)\n",
    "\n",
    "    \n",
    "    # convert to percentage and fit psychometric function\n",
    "    contrasts = signed_contrasts * 100\n",
    "    pars, L = psy.mle_fit_psycho(\n",
    "        np.vstack([contrasts, n_trials_stim, prob_choose_right]),\n",
    "        P_model='erf_psycho_2gammas',\n",
    "        parstart=np.array([np.mean(contrasts), 20., 0.05, 0.05]),\n",
    "        parmin=np.array([np.min(contrasts), 0., 0., 0.]),\n",
    "        parmax=np.array([np.max(contrasts), 100., 1, 1]))\n",
    "\n",
    "    return {\n",
    "        'signed_contrasts': signed_contrasts,\n",
    "        'n_trials_stim': n_trials_stim,\n",
    "        'n_trials_stim_right': n_trials_stim_right,\n",
    "        'prob_choose_right': prob_choose_right,\n",
    "        'bias': pars[0],\n",
    "        'threshold': pars[1],\n",
    "        'lapse_low': pars[2],\n",
    "        'lapse_high': pars[3]\n",
    "    }\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
